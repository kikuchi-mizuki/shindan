import cv2
import numpy as np
from PIL import Image
import logging
from typing import Dict, Any, Tuple

logger = logging.getLogger(__name__)

class ImageQualityService:
    """ç”»åƒå“è³ªè©•ä¾¡ã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self):
        self.quality_thresholds = {
            'high': 0.75,     # é«˜å“è³ªé–¾å€¤ï¼ˆå³æ ¼åŒ–ï¼‰
            'medium': 0.5,    # ä¸­å“è³ªé–¾å€¤ï¼ˆå³æ ¼åŒ–ï¼‰
            'low': 0.3        # ä½å“è³ªé–¾å€¤ï¼ˆå³æ ¼åŒ–ï¼‰
        }
        
        # å“è³ªã‚²ãƒ¼ãƒˆã®å³æ ¼ãªåˆ¤å®šåŸºæº–ï¼ˆç·©å’Œï¼‰
        self.strict_gate = {
            'min_sharpness': 0.3,    # æœ€å°é®®æ˜åº¦ï¼ˆç·©å’Œï¼‰
            'min_contrast': 0.3,     # æœ€å°ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆï¼ˆç·©å’Œï¼‰
            'max_noise': 0.2,        # æœ€å¤§ãƒã‚¤ã‚ºï¼ˆé€†æ•°ã€ç·©å’Œï¼‰
            'min_resolution': 600,   # æœ€å°è§£åƒåº¦ï¼ˆå¹…ã€ç·©å’Œï¼‰
            'max_skew': 20,          # æœ€å¤§å‚¾ãè§’åº¦ï¼ˆç·©å’Œï¼‰
            'min_text_ratio': 0.02   # æœ€å°æ–‡å­—å æœ‰ç‡ï¼ˆç·©å’Œï¼‰
        }
    
    def evaluate_image_quality(self, image_path: str) -> Dict[str, Any]:
        """ç”»åƒå“è³ªã‚’è©•ä¾¡"""
        try:
            # ç”»åƒèª­ã¿è¾¼ã¿
            image = cv2.imread(image_path)
            if image is None:
                return self._get_low_quality_result("ç”»åƒã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
            # å“è³ªè©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—
            sharpness_score = self._calculate_sharpness(image)
            contrast_score = self._calculate_contrast(image)
            noise_score = self._calculate_noise_level(image)
            complexity_score = self._calculate_complexity(image)
            
            # ç·åˆå“è³ªã‚¹ã‚³ã‚¢
            overall_score = (sharpness_score + contrast_score + noise_score + complexity_score) / 4
            
            # å³æ ¼ãªå“è³ªã‚²ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
            gate_check = self._check_strict_quality_gate(image, sharpness_score, contrast_score, noise_score)
            
            # å“è³ªãƒ¬ãƒ™ãƒ«åˆ¤å®š
            quality_level = self._determine_quality_level(overall_score)
            
            # å³æ ¼ã‚²ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã—ãŸå ´åˆã®ã¿å‡¦ç†ã‚’è¨±å¯
            should_process = gate_check['passed'] and quality_level in ['high', 'medium']
            
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’ãƒ­ã‚°ã«å‡ºåŠ›
            logger.info(f"Quality gate check: passed={gate_check['passed']}, quality_level={quality_level}, should_process={should_process}")
            if not gate_check['passed']:
                logger.info(f"Quality gate issues: {gate_check['issues']}")
            
            result = {
                'quality_level': quality_level,
                'overall_score': overall_score,
                'sharpness_score': sharpness_score,
                'contrast_score': contrast_score,
                'noise_score': noise_score,
                'complexity_score': complexity_score,
                'recommendation': self._get_recommendation(quality_level, gate_check),
                'should_process': should_process,
                'gate_check': gate_check
            }
            
            logger.info(f"Image quality evaluation: {quality_level} (score: {overall_score:.2f})")
            return result
            
        except Exception as e:
            logger.error(f"Error evaluating image quality: {e}")
            return self._get_low_quality_result(f"å“è³ªè©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _check_strict_quality_gate(self, image: np.ndarray, sharpness_score: float, contrast_score: float, noise_score: float) -> Dict[str, Any]:
        """å³æ ¼ãªå“è³ªã‚²ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯"""
        try:
            issues = []
            
            # 1. é®®æ˜åº¦ãƒã‚§ãƒƒã‚¯
            if sharpness_score < self.strict_gate['min_sharpness']:
                issues.append(f"é®®æ˜åº¦ä¸è¶³ (ã‚¹ã‚³ã‚¢: {sharpness_score:.2f})")
            
            # 2. ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆãƒã‚§ãƒƒã‚¯
            if contrast_score < self.strict_gate['min_contrast']:
                issues.append(f"ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆä¸è¶³ (ã‚¹ã‚³ã‚¢: {contrast_score:.2f})")
            
            # 3. ãƒã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
            if noise_score < self.strict_gate['max_noise']:
                issues.append(f"ãƒã‚¤ã‚ºéå¤š (ã‚¹ã‚³ã‚¢: {noise_score:.2f})")
            
            # 4. è§£åƒåº¦ãƒã‚§ãƒƒã‚¯
            height, width = image.shape[:2]
            if width < self.strict_gate['min_resolution']:
                issues.append(f"è§£åƒåº¦ä¸è¶³ (å¹…: {width}px)")
            
            # 5. å‚¾ããƒã‚§ãƒƒã‚¯
            skew_angle = self._calculate_skew_angle(image)
            if abs(skew_angle) > self.strict_gate['max_skew']:
                issues.append(f"å‚¾ãéå¤š (è§’åº¦: {skew_angle:.1f}Â°)")
            
            # 6. æ–‡å­—å æœ‰ç‡ãƒã‚§ãƒƒã‚¯
            text_ratio = self._calculate_text_ratio(image)
            if text_ratio < self.strict_gate['min_text_ratio']:
                issues.append(f"æ–‡å­—å æœ‰ç‡ä¸è¶³ ({text_ratio:.3f})")
            
            passed = len(issues) == 0
            
            return {
                'passed': passed,
                'issues': issues,
                'skew_angle': skew_angle,
                'text_ratio': text_ratio,
                'resolution': f"{width}x{height}"
            }
            
        except Exception as e:
            logger.error(f"Strict gate check error: {e}")
            return {
                'passed': False,
                'issues': [f"ã‚²ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}"],
                'skew_angle': 0,
                'text_ratio': 0,
                'resolution': "unknown"
            }
    
    def _calculate_sharpness(self, image: np.ndarray) -> float:
        """é®®æ˜åº¦ã‚’è¨ˆç®—ï¼ˆãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³åˆ†æ•£ï¼‰"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
            # æ­£è¦åŒ–ï¼ˆ0-1ã®ç¯„å›²ã«ï¼‰- é–¾å€¤ã‚’ç·©å’Œ
            sharpness_score = min(laplacian_var / 300, 1.0)
            # æœ€å°å€¤ã‚’è¨­å®šã—ã¦ã€æ¯”è¼ƒçš„ã‚¯ãƒªã‚¢ãªç”»åƒã§ã‚‚é©åˆ‡ãªã‚¹ã‚³ã‚¢ã‚’ä»˜ä¸
            return max(sharpness_score, 0.3)
        except:
            return 0.5
    
    def _calculate_contrast(self, image: np.ndarray) -> float:
        """ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’è¨ˆç®—"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            # æ¨™æº–åå·®ã§ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’è©•ä¾¡
            contrast = np.std(gray)
            # æ­£è¦åŒ–ï¼ˆ0-1ã®ç¯„å›²ã«ï¼‰- é–¾å€¤ã‚’ç·©å’Œ
            contrast_score = min(contrast / 30, 1.0)
            # æœ€å°å€¤ã‚’è¨­å®š
            return max(contrast_score, 0.3)
        except:
            return 0.5
    
    def _calculate_noise_level(self, image: np.ndarray) -> float:
        """ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ã‚’è¨ˆç®—"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ•ã‚£ãƒ«ã‚¿ã§ãƒã‚¤ã‚ºã‚’è©•ä¾¡
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
            noise = cv2.absdiff(gray, blurred)
            noise_level = np.mean(noise)
            # ãƒã‚¤ã‚ºãŒå°‘ãªã„ã»ã©é«˜ã‚¹ã‚³ã‚¢
            noise_score = max(0, 1.0 - (noise_level / 20))
            return noise_score
        except:
            return 0.5
    
    def _calculate_skew_angle(self, image: np.ndarray) -> float:
        """ç”»åƒã®å‚¾ãè§’åº¦ã‚’è¨ˆç®—"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            # ã‚¨ãƒƒã‚¸æ¤œå‡º
            edges = cv2.Canny(gray, 50, 150, apertureSize=3)
            # ç›´ç·šæ¤œå‡º
            lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=100)
            
            if lines is None:
                return 0.0
            
            angles = []
            # linesã®å½¢çŠ¶ã‚’å®‰å…¨ã«å‡¦ç†
            if len(lines.shape) == 3:  # (1, N, 2) ã®å½¢çŠ¶
                lines = lines.reshape(-1, 2)
            
            for i, (rho, theta) in enumerate(lines[:10]):  # æœ€åˆã®10æœ¬ã®ç·šã®ã¿
                try:
                    angle = theta * 180 / np.pi
                    if angle < 90:
                        angles.append(angle)
                    else:
                        angles.append(angle - 180)
                except (ValueError, TypeError) as e:
                    logger.debug(f"Line {i} processing error: {e}")
                    continue
            
            if not angles:
                return 0.0
            
            # ä¸­å¤®å€¤ã§å‚¾ãã‚’æ¨å®š
            return np.median(angles)
            
        except Exception as e:
            logger.warning(f"Skew angle calculation error: {e}")
            return 0.0
    
    def _calculate_text_ratio(self, image: np.ndarray) -> float:
        """æ–‡å­—å æœ‰ç‡ã‚’è¨ˆç®—"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            # äºŒå€¤åŒ–
            _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            # æ–‡å­—é ˜åŸŸã®å‰²åˆã‚’è¨ˆç®—
            text_pixels = np.sum(binary == 0)  # é»’ã„éƒ¨åˆ†ï¼ˆæ–‡å­—ï¼‰
            total_pixels = binary.size
            return text_pixels / total_pixels
            
        except Exception as e:
            logger.warning(f"Text ratio calculation error: {e}")
            return 0.0
    
    def _calculate_complexity(self, image: np.ndarray) -> float:
        """ç”»åƒã®è¤‡é›‘åº¦ã‚’è¨ˆç®—"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            # ã‚¨ãƒƒã‚¸æ¤œå‡ºã§è¤‡é›‘åº¦ã‚’è©•ä¾¡
            edges = cv2.Canny(gray, 50, 150)
            edge_density = np.sum(edges > 0) / (edges.shape[0] * edges.shape[1])
            # è¤‡é›‘åº¦è©•ä¾¡ã‚’æ”¹å–„ - ãƒ¡ãƒ¢ã‚¢ãƒ—ãƒªã®ã‚ˆã†ãªæ¯”è¼ƒçš„å˜ç´”ãªç”»åƒã‚‚é©åˆ‡ã«è©•ä¾¡
            if edge_density < 0.005:  # éå¸¸ã«å˜ç´”ï¼ˆç™½ç´™ãªã©ï¼‰
                complexity_score = 0.2
            elif edge_density < 0.02:  # é©åº¦ã«å˜ç´”ï¼ˆãƒ¡ãƒ¢ã‚¢ãƒ—ãƒªãªã©ï¼‰
                complexity_score = 0.7
            elif edge_density > 0.15:  # éå¸¸ã«è¤‡é›‘
                complexity_score = 0.4
            else:  # é©åº¦ãªè¤‡é›‘åº¦
                complexity_score = 0.8
            return complexity_score
        except:
            return 0.5
    
    def _determine_quality_level(self, overall_score: float) -> str:
        """å“è³ªãƒ¬ãƒ™ãƒ«ã‚’åˆ¤å®š"""
        if overall_score >= self.quality_thresholds['high']:
            return 'high'
        elif overall_score >= self.quality_thresholds['medium']:
            return 'medium'
        else:
            return 'low'
    
    def _get_recommendation(self, quality_level: str, gate_check: Dict[str, Any] = None) -> str:
        """å“è³ªãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸæ¨å¥¨äº‹é …"""
        if gate_check and not gate_check.get('passed', True):
            issues = gate_check.get('issues', [])
            recommendation = "ğŸš« **å“è³ªã‚²ãƒ¼ãƒˆæœªé€šé**\n\n"
            recommendation += "ä»¥ä¸‹ã®å•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸï¼š\n"
            for issue in issues:
                recommendation += f"â€¢ {issue}\n"
            recommendation += "\n**æ”¹å–„æ–¹æ³•ï¼š**\n"
            recommendation += "â€¢ 1ãƒšãƒ¼ã‚¸ãšã¤æ’®å½±ã—ã¦ãã ã•ã„\n"
            recommendation += "â€¢ çœŸä¸Šã‹ã‚‰æ’®å½±ã—ã¦ãã ã•ã„\n"
            recommendation += "â€¢ æ˜ã‚‹ã„å ´æ‰€ã§æ’®å½±ã—ã¦ãã ã•ã„\n"
            recommendation += "â€¢ å½±ã‚„åå°„ã‚’é¿ã‘ã¦ãã ã•ã„\n"
            recommendation += "â€¢ æ›¸é¡ã‚¹ã‚­ãƒ£ãƒ³ã‚¢ãƒ—ãƒªã®ä½¿ç”¨ã‚’æ¨å¥¨ã—ã¾ã™\n"
            return recommendation
        
        recommendations = {
            'high': "âœ… ç”»åƒå“è³ªã¯è‰¯å¥½ã§ã™ã€‚è–¬å‰¤åã®èª­ã¿å–ã‚Šã‚’ç¶šè¡Œã—ã¾ã™ã€‚",
            'medium': "âš ï¸ ç”»åƒå“è³ªã¯ä¸­ç¨‹åº¦ã§ã™ã€‚ã‚ˆã‚Šé®®æ˜ãªç”»åƒã§ã®å†æ’®å½±ã‚’æ¨å¥¨ã—ã¾ã™ã€‚",
            'low': "âŒ ç”»åƒå“è³ªãŒä½ã„ãŸã‚ã€è–¬å‰¤åã®èª­ã¿å–ã‚ŠãŒå›°é›£ã§ã™ã€‚"
        }
        return recommendations.get(quality_level, "ç”»åƒå“è³ªã‚’è©•ä¾¡ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
    
    def _get_low_quality_result(self, error_message: str) -> Dict[str, Any]:
        """ä½å“è³ªçµæœã‚’è¿”ã™"""
        return {
            'quality_level': 'low',
            'overall_score': 0.0,
            'sharpness_score': 0.0,
            'contrast_score': 0.0,
            'noise_score': 0.0,
            'complexity_score': 0.0,
            'recommendation': error_message,
            'should_process': False
        }
    
    def generate_quality_guide(self, quality_level: str) -> str:
        """å“è³ªãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸã‚¬ã‚¤ãƒ‰ã‚’ç”Ÿæˆ"""
        guides = {
            'high': self._generate_high_quality_guide(),
            'medium': self._generate_medium_quality_guide(),
            'low': self._generate_low_quality_guide()
        }
        return guides.get(quality_level, "ã‚¬ã‚¤ãƒ‰ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    def _generate_high_quality_guide(self) -> str:
        """é«˜å“è³ªç”»åƒç”¨ã‚¬ã‚¤ãƒ‰"""
        return """âœ… **é«˜å“è³ªãªç”»åƒã§ã™ï¼**
        
è–¬å‰¤ã®æ¤œå‡ºã¨è¨ºæ–­ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
çµæœã‚’ç¢ºèªã—ã¦ã€Œè¨ºæ–­ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚"""
    
    def _generate_medium_quality_guide(self) -> str:
        """ä¸­å“è³ªç”»åƒç”¨ã‚¬ã‚¤ãƒ‰"""
        return """âš ï¸ **ä¸­å“è³ªãªç”»åƒã§ã™**

è–¬å‰¤ã®æ¤œå‡ºã‚’è©¦ã¿ã¾ã™ãŒã€ä»¥ä¸‹ã®ç‚¹ã«ã”æ³¨æ„ãã ã•ã„ï¼š

â€¢ æ¤œå‡ºçµæœã‚’å¿…ãšç¢ºèªã—ã¦ãã ã•ã„
â€¢ ä¸è¶³ã—ã¦ã„ã‚‹è–¬å‰¤ãŒã‚ã‚Œã°æ‰‹å‹•ã§è¿½åŠ ã—ã¦ãã ã•ã„
â€¢ èª¤æ¤œå‡ºãŒã‚ã‚Œã°ä¿®æ­£ã—ã¦ãã ã•ã„

**æ‰‹å‹•è¿½åŠ æ–¹æ³•**: ã€Œè–¬å‰¤è¿½åŠ ï¼šè–¬å‰¤åã€ã¨å…¥åŠ›"""
    
    def _generate_low_quality_guide(self) -> str:
        """ä½å“è³ªç”»åƒç”¨ã‚¬ã‚¤ãƒ‰"""
        return """âŒ **ç”»åƒã®å“è³ªãŒä½ã„ãŸã‚ã€è‡ªå‹•æ¤œå‡ºãŒå›°é›£ã§ã™**

**æ¨å¥¨ã•ã‚Œã‚‹å¯¾å‡¦æ³•ï¼š**

1ï¸âƒ£ **ç”»åƒã®æ”¹å–„**
â€¢ æ˜ã‚‹ã„å ´æ‰€ã§æ’®å½±
â€¢ ã‚«ãƒ¡ãƒ©ã‚’å®‰å®šã•ã›ã‚‹
â€¢ æ–‡å­—ãŒã¯ã£ãã‚Šè¦‹ãˆã‚‹ã‚ˆã†ã«ã™ã‚‹
â€¢ å½±ã‚„åå°„ã‚’é¿ã‘ã‚‹

2ï¸âƒ£ **æ‰‹å‹•å…¥åŠ›**
ä»¥ä¸‹ã®å½¢å¼ã§è–¬å‰¤ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š
```
è–¬å‰¤è¿½åŠ ï¼šã‚¯ãƒ©ãƒªã‚¹ãƒ­ãƒã‚¤ã‚·ãƒ³
è–¬å‰¤è¿½åŠ ï¼šãƒ™ãƒ«ã‚½ãƒ ãƒ©
è–¬å‰¤è¿½åŠ ï¼šãƒ‡ãƒ“ã‚´
```

3ï¸âƒ£ **ãƒ¡ãƒ¢ã‚¢ãƒ—ãƒªã®ä½¿ç”¨**
â€¢ è–¬å‰¤åã‚’ãƒ¡ãƒ¢ã‚¢ãƒ—ãƒªã«è¨˜å…¥
â€¢ ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’æ’®å½±
â€¢ å†åº¦é€ä¿¡ã—ã¦ãã ã•ã„

**ä¾‹**:
```
ã‚¯ãƒ©ãƒªã‚¹ãƒ­ãƒã‚¤ã‚·ãƒ³
ãƒ™ãƒ«ã‚½ãƒ ãƒ©
ãƒ‡ãƒ“ã‚´
ãƒ­ã‚¼ãƒ¬ãƒ 
ãƒ•ãƒ«ãƒœã‚­ã‚µãƒŸãƒ³
ã‚¢ãƒ ãƒ­ã‚¸ãƒ”ãƒ³
ã‚¨ã‚½ãƒ¡ãƒ—ãƒ©ã‚¾ãƒ¼ãƒ«
```"""
